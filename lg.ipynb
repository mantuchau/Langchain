{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Adobe's headquarters is located in San Jose, California, United States. \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "import os\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \" \"\n",
    "\n",
    "# Initialize the OpenAI model\n",
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "# Query the model\n",
    "response = llm(\"Where is Adobe's headquarters located in the world?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a resturent for Indian food.suggest some fancy name for this.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template=\"I want to open a resturent for {cuisine} food.suggest some fancy name for this.\"\n",
    ")\n",
    "prompt_template_name.format(cuisine=\"Indian\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. \"Cinco de Mayo Cantina\"\\n2. \"Sabor Mexicano\"\\n3. \"La Fiesta Mexicana\"\\n4. \"El Ranchero\\'s Cocina\"\\n5. \"Taco Tres Amigos\"\\n6. \"Hacienda del Sol\"\\n7. \"El Diablo\\'s Kitchen\"\\n8. \"Amor y Tacos\"\\n9. \"La Cocina de Mexico\"\\n10. \"Fiesta Mexicana Grill\"\\n11. \"Taco Fiesta Co.\"\\n12. \"Casa de Nachos\"\\n13. \"Chili Pepper Palace\"\\n14. \"The Burrito Bar\"\\n15. \"Salsa y Cerveza\"'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "chain.run(\"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template=\"I want to open a resturent for {cuisine} food.suggest some fancy name for this.\"\n",
    ")\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables = ['reasturent_name'],\n",
    "    template=\"\"\"Suggest some menu items for {reasturent_name} food.return it as a comma separated list.\"\"\"\n",
    ")\n",
    "food_item_chain=LLMChain(llm=llm,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Spice Paradise:\n",
      "- Chicken Tikka Masala\n",
      "- Vegetable Korma\n",
      "- Lamb Vindaloo\n",
      "- Chana Masala\n",
      "- Aloo Gobi\n",
      "- Palak Paneer\n",
      "- Tandoori Chicken\n",
      "- Seekh Kebab\n",
      "- Garlic Naan\n",
      "- Mango Lassi\n",
      "\n",
      "2. Tandoori Temptations:\n",
      "- Tandoori Shrimp\n",
      "- Tandoori Chicken\n",
      "- Tandoori Lamb Chops\n",
      "- Vegetable Tandoori Platter\n",
      "- Butter Chicken\n",
      "- Lamb Rogan Josh\n",
      "- Chicken Tikka Masala\n",
      "- Garlic Naan\n",
      "- Mango Lassi\n",
      "\n",
      "3. Masala Magic:\n",
      "- Chicken Biryani\n",
      "- Paneer Tikka Masala\n",
      "- Dal Makhani\n",
      "- Lamb Korma\n",
      "- Vegetable Jalfrezi\n",
      "- Malai Kofta\n",
      "- Tandoori Chicken\n",
      "- Garlic Naan\n",
      "- Mango Lassi\n",
      "\n",
      "4. Curry Craze:\n",
      "- Lamb Curry\n",
      "- Chicken Madras\n",
      "- Vegetable Curry\n",
      "- Prawn Vindaloo\n",
      "- Aloo Palak\n",
      "- Chicken Korma\n",
      "- Garlic Naan\n",
      "- Mango Lassi\n",
      "\n",
      "5. Flavors of India:\n",
      "- Chicken Tikka Masala\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains=[name_chain,food_item_chain])\n",
    "response=chain.run(\"Indian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template=\"I want to open a resturent for {cuisine} food.suggest some fancy name for this.\"\n",
    ")\n",
    "name_chain=LLMChain(llm=llm,prompt=prompt_template_name,output_key=\"reasturent_name\")\n",
    "prompt_template_name=PromptTemplate(\n",
    "    input_variables = ['reasturent_name'],\n",
    "    template=\"\"\"Suggest some menu items for {reasturent_name} food.return it as a comma separated list.\"\"\"\n",
    ")\n",
    "food_item_chain=LLMChain(llm=llm,prompt=prompt_template_name,output_key=\"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14280\\1711094110.py:9: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = chain({\"cuisine\": \"Arabic\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Arabic', 'reasturent_name': '\\n\\n1. \"Saffron Oasis\"\\n2. \"Arabian Nights Bistro\"\\n3. \"Falafel Frenzy\"\\n4. \"Shawarma Shangri-La\"\\n5. \"Mediterranean Majesty\"\\n6. \"Sultan\\'s Feast\"\\n7. \"Hummus Haven\"\\n8. \"Olive Oasis\"\\n9. \"Spice Souk\"\\n10. \"Baklava Bliss\"', 'menu_items': '\\n\\n1. \"Saffron-infused chicken kebabs\"\\n2. \"Lamb shawarma platter\"\\n3. \"Falafel wrap with tahini sauce\"\\n4. \"Shawarma platter with hummus and pita\"\\n5. \"Grilled Mediterranean vegetables with herb couscous\"\\n6. \"Lamb tagine with dried fruits and nuts\"\\n7. \"Hummus trio (classic, roasted red pepper, and garlic)\"\\n8. \"Olive tapenade with warm pita bread\"\\n9. \"Spicy beef koftas with yogurt sauce\"\\n10. \"Baklava with pistachios and honey drizzle\"'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "chain = SequentialChain(\n",
    "    chains=[name_chain, food_item_chain],\n",
    "    input_variables=[\"cuisine\"],\n",
    "    output_variables=[\"reasturent_name\", \"menu_items\"],\n",
    ")\n",
    "\n",
    "# Execute the chain\n",
    "result = chain({\"cuisine\": \"Arabic\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14280\\3055695214.py:5: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use :meth:`~Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc.` instead.\n",
      "  agent=initialize_agent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out the current year and then subtract 1971 from the current year to find out Elon Musk's age in that year.\n",
      "Action: Calculator\n",
      "Action Input: Subtract current year by 1971\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 49\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now have Elon Musk's age in 2023.\n",
      "Action: Calculator\n",
      "Action Input: Add 3 to 49\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 52\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Elon Musk will be 52 years old in 2023.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Elon Musk will be 52 years old in 2023.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentType ,initialize_agent ,load_tools\n",
    "from langchain.llms import OpenAI\n",
    "tools=load_tools([\"wikipedia\",\"llm-math\"],llm=llm)\n",
    "\n",
    "agent=initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    "\n",
    ")\n",
    "agent.run(\"What is elon musk age in 2023\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpsecret_key import serpapi_key\n",
    "os.environ['SERPAPI_API_KEY']=serpapi_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should use a search engine to find the answer.\n",
      "Action: Search\n",
      "Action Input: \"US GDP 2022\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[\"The U.S. is a country of 50 states covering a vast swath of North America, with Alaska in the northwest and Hawaii extending the nation’s presence into the Pacific Ocean. Major Atlantic Coast cities are New York, a global finance and culture center, and capital Washington, DC. Midwestern metropolis Chicago is known for influential architecture and on the west coast, Los Angeles' Hollywood is famed for filmmaking. ― Google\", 'United States type: Country in North America.', 'United States entity_type: countries, locations, travel, competitions, military.', 'United States kgmid: /m/09c7w0.', 'Current-dollar GDP increased 9.2 percent, or $2.15 trillion, in 2022 to a level of $25.46 trillion, compared with an increase of 10.7 percent, ...', 'Current-dollar GDP increased 9.2 percent, or $2.15 trillion, in 2022 to a level of $25.46 trillion, compared with an increase of 10.7 percent, ...', 'The Gross Domestic Product (GDP) in the United States was worth 27360.94 billion US dollars in 2023, according to official data from the World Bank.', 'Real GDP (constant, inflation adjusted) of the United States of America reached $18,924,600,000,000 in 2022. · GDP Growth Rate in 2022 was 2.06%, representing a ...', 'Full Year GDP Growth in the United States increased to 2.90 percent in 2023 from 2.50 percent in 2022.', 'U.S. gdp for 2022 was $25,744.11B, a 9.11% increase from 2021. U.S. gdp for 2021 was $23,594.03B, a 10.65% increase from 2020. U.S. gdp for 2020 was $21,322.95B ...', 'In 2023, the US GDP increased from the previous year to about 27.36 trillion US dollars. This increase in GDP can be attributed to a continued rebound from the ...', 'In 2023 the real gross domestic product (GDP) of the United States increased by 2.5 percent compared to 2022.', 'Gross domestic product (GDP), the featured measure of US output, is the market value of the goods and services produced by labor and property located in the ...', 'US gross domestic product (GDP) increased 1.9% in 2022 and another 2.5% in 2023. Year-over-year inflation — the rate at which consumer prices increase — was 3.1 ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to calculate the GDP.\n",
      "Action: Calculator\n",
      "Action Input: 25.46 trillion + 9.2%\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 27802320000000.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should convert the answer to US dollars.\n",
      "Action: Calculator\n",
      "Action Input: 27802320000000.0 * 1.19\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 33084760800000.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The US GDP in 2022 is approximately $33.08 trillion.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The US GDP in 2022 is approximately $33.08 trillion.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=OpenAI(temperature=0)\n",
    "tools=load_tools([\"serpapi\",\"llm-math\"], llm=llm)\n",
    "agent=initialize_agent(tools,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)\n",
    "agent.run(\"What is US GDP in 2022?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Tacos (beef, chicken, or fish)\n",
      "2. Burritos (bean, beef, or chicken)\n",
      "3. Enchiladas (cheese, chicken, or beef)\n",
      "4. Quesadillas (cheese, chicken, or steak)\n",
      "5. Nachos (with beef, chicken, or vegetarian)\n",
      "6. Fajitas (chicken, beef, or shrimp)\n",
      "7. Chimichangas (beef, chicken, or pork)\n",
      "8. Tamales (chicken, pork, or vegetarian)\n",
      "9. Carne Asada (grilled steak)\n",
      "10. Carnitas (slow-cooked pork)\n",
      "11. Chile Rellenos (stuffed peppers)\n",
      "12. Guacamole and chips\n",
      "13. Salsa and chips\n",
      "14. Mexican rice\n",
      "15. Refried beans\n",
      "16. Flautas (crispy rolled tacos)\n",
      "17. Pozole (traditional soup with hominy and meat)\n",
      "18. Tostadas (crispy tortillas with toppings)\n",
      "19. Churros (fried dough pastry)\n",
      "20. Horchata (traditional rice milk drink)\n"
     ]
    }
   ],
   "source": [
    "chain=  LLMChain(llm=llm,prompt=prompt_template_name)\n",
    "name=chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14280\\3716757651.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferMemory()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Tacos (beef, chicken, or fish)\n",
      "2. Burritos (bean, beef, or chicken)\n",
      "3. Enchiladas (cheese, chicken, or beef)\n",
      "4. Quesadillas (cheese, chicken, or steak)\n",
      "5. Nachos (with beef, chicken, or vegetarian)\n",
      "6. Fajitas (chicken, beef, or shrimp)\n",
      "7. Chimichangas (beef, chicken, or pork)\n",
      "8. Tamales (chicken, pork, or vegetarian)\n",
      "9. Chiles Rellenos (stuffed peppers with cheese or meat)\n",
      "10. Carne Asada (grilled steak)\n",
      "11. Carnitas (slow-cooked pork)\n",
      "12. Pozole (traditional Mexican soup with pork or chicken)\n",
      "13. Flautas (crispy rolled tacos with chicken or beef)\n",
      "14. Sopes (thick corn tortillas topped with meat, beans, and cheese)\n",
      "15. Churros (fried dough pastry with cinnamon sugar)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory=ConversationBufferMemory()\n",
    "chain=LLMChain(llm=llm,prompt=prompt_template_name,memory=memory)\n",
    "name=chain.run(\"Mexican\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Mexican\n",
      "AI: \n",
      "\n",
      "1. Tacos (beef, chicken, or fish)\n",
      "2. Burritos (bean, beef, or chicken)\n",
      "3. Enchiladas (cheese, chicken, or beef)\n",
      "4. Quesadillas (cheese, chicken, or steak)\n",
      "5. Nachos (with beef, chicken, or vegetarian)\n",
      "6. Fajitas (chicken, beef, or shrimp)\n",
      "7. Chimichangas (beef, chicken, or pork)\n",
      "8. Tamales (chicken, pork, or vegetarian)\n",
      "9. Chiles Rellenos (stuffed peppers with cheese or meat)\n",
      "10. Carne Asada (grilled steak)\n",
      "11. Carnitas (slow-cooked pork)\n",
      "12. Pozole (traditional Mexican soup with pork or chicken)\n",
      "13. Flautas (crispy rolled tacos with chicken or beef)\n",
      "14. Sopes (thick corn tortillas topped with meat, beans, and cheese)\n",
      "15. Churros (fried dough pastry with cinnamon sugar)\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14280\\4243084069.py:2: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
      "  convo=ConversationChain(llm=OpenAI(temperature=0.7))\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "convo=ConversationChain(llm=OpenAI(temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_14280\\3202311003.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory=ConversationBufferWindowMemory(k=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" The 1975 World Cup was won by the West Indies cricket team. They defeated Australia in the final match by 17 runs. It was the second time the West Indies had won the World Cup, with their first victory in 1975. The captain of the West Indies team was Clive Lloyd, who was also named the Player of the Tournament. The final match was held at Lord's Cricket Ground in London, England, and was attended by over 26,000 spectators. \""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "memory=ConversationBufferWindowMemory(k=1)\n",
    "convo=ConversationChain(\n",
    "    llm=OpenAI(temperature=0.6),\n",
    "    memory=memory\n",
    ")\n",
    "convo.run(\"Who win the world cup in 1975?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
